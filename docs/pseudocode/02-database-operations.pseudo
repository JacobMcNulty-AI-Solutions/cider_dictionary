# Database Operations Pseudocode
# Cider Dictionary - Foundation Architecture Phase 1

## Overview
This pseudocode defines the database operations layer for Firebase Firestore
with offline-first architecture, supporting CRUD operations, query patterns,
and comprehensive sync mechanisms.

## Database Service Architecture

### Firebase Service Manager
```
ALGORITHM: DatabaseServiceManager
PURPOSE: Centralized database operations with offline-first pattern

CLASS DatabaseServiceManager:
    PROPERTIES:
        firestore: FirebaseFirestore
        localDB: SQLiteDatabase
        networkMonitor: NetworkMonitor
        syncQueue: OperationQueue
        conflictResolver: ConflictResolver

    CONSTRUCTOR:
        INPUT: Firebase configuration
        OUTPUT: Initialized database service

        BEGIN
            this.firestore = initializeFirestore(config)
            this.localDB = initializeSQLite()
            this.networkMonitor = NetworkMonitor.getInstance()
            this.syncQueue = OperationQueue.getInstance()
            this.conflictResolver = ConflictResolver.getInstance()

            // Enable offline persistence
            this.firestore.enablePersistence({
                synchronizeTabs: false,
                experimentalForceOwningTab: true
            })

            // Setup network change listeners
            this.networkMonitor.onStateChange(this.handleNetworkChange)
        END

    FUNCTION handleNetworkChange(isOnline):
        BEGIN
            IF isOnline THEN
                this.syncQueue.processPendingOperations()
            END IF
        END
```

## CRUD Operations - Ciders

### Create Operations
```
ALGORITHM: CreateCider
PURPOSE: Create new cider with duplicate prevention and offline support

FUNCTION createCider(ciderData):
    INPUT: CiderMasterRecord data
    OUTPUT: Promise<CiderMasterRecord | Error>

    PRECONDITIONS:
        - ciderData must pass validation
        - User must be authenticated

    BEGIN
        // Step 1: Validate input data
        validationResult = validateCiderData(ciderData)
        IF NOT validationResult.isValid THEN
            THROW ValidationError(validationResult.errors)
        END IF

        // Step 2: Check for duplicates
        duplicateCheck = await checkForDuplicates(ciderData.name, ciderData.brand)
        IF duplicateCheck.isDuplicate THEN
            THROW DuplicateError("Cider already exists", duplicateCheck.existing)
        END IF

        // Step 3: Prepare cider record
        newCider = {
            id: generateUUID(),
            userId: getCurrentUserId(),
            ...ciderData,
            timesTried: 0,
            createdAt: getCurrentTimestamp(),
            updatedAt: getCurrentTimestamp(),
            syncStatus: "pending"
        }

        // Step 4: Save locally first (offline-first)
        await saveToLocalDB("ciders", newCider)

        // Step 5: Queue for Firebase sync
        syncOperation = {
            type: "CREATE",
            collection: "ciders",
            documentId: newCider.id,
            data: newCider,
            timestamp: getCurrentTimestamp()
        }
        this.syncQueue.enqueue(syncOperation)

        // Step 6: Attempt immediate sync if online
        IF this.networkMonitor.isOnline() THEN
            await this.syncToFirebase(syncOperation)
        END IF

        RETURN newCider
    END

    POSTCONDITIONS:
        - Cider saved locally
        - Sync operation queued
        - User notified of success

FUNCTION checkForDuplicates(name, brand):
    INPUT: Cider name and brand strings
    OUTPUT: DuplicateCheckResult

    BEGIN
        normalizedName = normalizeName(name)
        normalizedBrand = normalizeName(brand)

        // Check local database first
        localCiders = await queryLocalDB(
            "SELECT * FROM ciders WHERE user_id = ? AND name_normalized = ? AND brand_normalized = ?",
            [getCurrentUserId(), normalizedName, normalizedBrand]
        )

        IF localCiders.length > 0 THEN
            RETURN {
                isDuplicate: true,
                existing: localCiders[0],
                similarity: 1.0
            }
        END IF

        // Check for similar names using fuzzy matching
        allUserCiders = await queryLocalDB(
            "SELECT * FROM ciders WHERE user_id = ?",
            [getCurrentUserId()]
        )

        FOR EACH cider IN allUserCiders DO
            similarity = calculateSimilarity(name + brand, cider.name + cider.brand)
            IF similarity > 0.8 THEN
                RETURN {
                    isDuplicate: false,
                    isSimilar: true,
                    existing: cider,
                    similarity: similarity
                }
            END IF
        END FOR

        RETURN {
            isDuplicate: false,
            isSimilar: false,
            similarity: 0
        }
    END

FUNCTION calculateSimilarity(str1, str2):
    INPUT: Two strings to compare
    OUTPUT: Similarity score between 0 and 1

    BEGIN
        // Use Levenshtein distance for fuzzy matching
        distance = levenshteinDistance(str1.toLowerCase(), str2.toLowerCase())
        maxLength = Math.max(str1.length, str2.length)

        IF maxLength == 0 THEN
            RETURN 1.0
        END IF

        RETURN 1 - (distance / maxLength)
    END
```

### Read Operations
```
ALGORITHM: GetCiders
PURPOSE: Retrieve cider collection with optimized queries

FUNCTION getCiderCollection(filters, sortBy, limit):
    INPUT: Optional filters, sort criteria, result limit
    OUTPUT: Promise<CiderMasterRecord[]>

    BEGIN
        // Step 1: Try local database first (offline-first)
        localQuery = buildLocalQuery(filters, sortBy, limit)
        localResults = await executeLocalQuery(localQuery)

        // Step 2: Return local results immediately
        IF NOT this.networkMonitor.isOnline() THEN
            RETURN localResults
        END IF

        // Step 3: Fetch updates from Firebase in background
        lastSyncTime = await getLastSyncTimestamp("ciders")

        IF shouldRefreshFromFirebase(lastSyncTime) THEN
            backgroundSync = this.syncFromFirebase("ciders", lastSyncTime)
            // Don't wait for background sync
        END IF

        RETURN localResults
    END

FUNCTION getCiderById(ciderId):
    INPUT: Cider ID string
    OUTPUT: Promise<CiderMasterRecord | null>

    BEGIN
        // Check local cache first
        localCider = await queryLocalDB(
            "SELECT * FROM ciders WHERE id = ? AND user_id = ?",
            [ciderId, getCurrentUserId()]
        )

        IF localCider.exists THEN
            RETURN localCider.data
        END IF

        // Fallback to Firebase if online
        IF this.networkMonitor.isOnline() THEN
            firebaseCider = await this.firestore
                .collection("ciders")
                .doc(ciderId)
                .get()

            IF firebaseCider.exists THEN
                ciderData = firebaseCider.data()
                // Cache locally for future offline access
                await saveToLocalDB("ciders", ciderData)
                RETURN ciderData
            END IF
        END IF

        RETURN null
    END

FUNCTION buildLocalQuery(filters, sortBy, limit):
    INPUT: Query parameters
    OUTPUT: SQL query string and parameters

    BEGIN
        queryParts = ["SELECT * FROM ciders WHERE user_id = ?"]
        params = [getCurrentUserId()]

        // Add filters
        IF filters.name IS NOT NULL THEN
            queryParts.append("AND name LIKE ?")
            params.append("%" + filters.name + "%")
        END IF

        IF filters.brand IS NOT NULL THEN
            queryParts.append("AND brand LIKE ?")
            params.append("%" + filters.brand + "%")
        END IF

        IF filters.minRating IS NOT NULL THEN
            queryParts.append("AND overall_rating >= ?")
            params.append(filters.minRating)
        END IF

        // Add sorting
        SWITCH sortBy:
            CASE "name":
                queryParts.append("ORDER BY name ASC")
            CASE "rating":
                queryParts.append("ORDER BY overall_rating DESC")
            CASE "recent":
                queryParts.append("ORDER BY updated_at DESC")
            DEFAULT:
                queryParts.append("ORDER BY name ASC")
        END SWITCH

        // Add limit
        IF limit IS NOT NULL THEN
            queryParts.append("LIMIT ?")
            params.append(limit)
        END IF

        RETURN {
            query: queryParts.join(" "),
            params: params
        }
    END
```

### Update Operations
```
ALGORITHM: UpdateCider
PURPOSE: Update cider with conflict resolution and optimistic locking

FUNCTION updateCider(ciderId, updateData):
    INPUT: Cider ID and update data
    OUTPUT: Promise<CiderMasterRecord | Error>

    PRECONDITIONS:
        - ciderId must exist
        - updateData must pass validation
        - User must own the cider

    BEGIN
        // Step 1: Get current version
        currentCider = await getCiderById(ciderId)
        IF currentCider IS NULL THEN
            THROW NotFoundError("Cider not found")
        END IF

        // Step 2: Validate update data
        validationResult = validateCiderData({...currentCider, ...updateData})
        IF NOT validationResult.isValid THEN
            THROW ValidationError(validationResult.errors)
        END IF

        // Step 3: Create updated record
        updatedCider = {
            ...currentCider,
            ...updateData,
            updatedAt: getCurrentTimestamp(),
            version: currentCider.version + 1,
            syncStatus: "pending"
        }

        // Step 4: Save locally with optimistic locking
        updateResult = await updateLocalDB(
            "UPDATE ciders SET ? WHERE id = ? AND user_id = ? AND version = ?",
            [updatedCider, ciderId, getCurrentUserId(), currentCider.version]
        )

        IF updateResult.affectedRows == 0 THEN
            THROW ConflictError("Cider was modified by another process")
        END IF

        // Step 5: Queue for Firebase sync
        syncOperation = {
            type: "UPDATE",
            collection: "ciders",
            documentId: ciderId,
            data: updatedCider,
            previousVersion: currentCider.version,
            timestamp: getCurrentTimestamp()
        }
        this.syncQueue.enqueue(syncOperation)

        // Step 6: Attempt immediate sync if online
        IF this.networkMonitor.isOnline() THEN
            await this.syncToFirebase(syncOperation)
        END IF

        RETURN updatedCider
    END

FUNCTION updateCiderRating(ciderId, newRating):
    INPUT: Cider ID and new rating
    OUTPUT: Promise<CiderMasterRecord>

    BEGIN
        // Optimized path for frequent rating updates
        currentCider = await getCiderById(ciderId)

        // Calculate updated average if multiple ratings exist
        ratingHistory = currentCider.ratingHistory || []
        ratingHistory.append({
            rating: newRating,
            timestamp: getCurrentTimestamp()
        })

        // Calculate new average
        totalRatings = ratingHistory.length
        averageRating = ratingHistory.reduce((sum, r) => sum + r.rating, 0) / totalRatings

        updateData = {
            overallRating: averageRating,
            ratingHistory: ratingHistory
        }

        RETURN await updateCider(ciderId, updateData)
    END
```

### Delete Operations
```
ALGORITHM: DeleteCider
PURPOSE: Soft delete with data preservation for experiences

FUNCTION deleteCider(ciderId):
    INPUT: Cider ID to delete
    OUTPUT: Promise<boolean>

    BEGIN
        // Step 1: Verify ownership
        cider = await getCiderById(ciderId)
        IF cider IS NULL THEN
            THROW NotFoundError("Cider not found")
        END IF

        // Step 2: Check for existing experiences
        experienceCount = await countExperiences(ciderId)

        IF experienceCount > 0 THEN
            // Soft delete to preserve experience data integrity
            softDeleteData = {
                isDeleted: true,
                deletedAt: getCurrentTimestamp(),
                syncStatus: "pending"
            }
            await updateCider(ciderId, softDeleteData)
        ELSE
            // Hard delete if no experiences exist
            await deleteFromLocalDB("ciders", ciderId)

            syncOperation = {
                type: "DELETE",
                collection: "ciders",
                documentId: ciderId,
                timestamp: getCurrentTimestamp()
            }
            this.syncQueue.enqueue(syncOperation)
        END IF

        RETURN true
    END
```

## CRUD Operations - Experiences

### Create Experience
```
ALGORITHM: CreateExperience
PURPOSE: Log drinking experience with automatic venue consolidation

FUNCTION createExperience(experienceData):
    INPUT: ExperienceLog data
    OUTPUT: Promise<ExperienceLog>

    BEGIN
        // Step 1: Validate experience data
        validationResult = validateExperienceData(experienceData)
        IF NOT validationResult.isValid THEN
            THROW ValidationError(validationResult.errors)
        END IF

        // Step 2: Verify cider exists
        cider = await getCiderById(experienceData.ciderId)
        IF cider IS NULL THEN
            THROW NotFoundError("Referenced cider not found")
        END IF

        // Step 3: Process venue information
        venueData = await processVenueData(experienceData.venue)

        // Step 4: Calculate derived fields
        pricePerMl = experienceData.price / experienceData.containerSize

        newExperience = {
            id: generateUUID(),
            userId: getCurrentUserId(),
            ...experienceData,
            venue: venueData,
            pricePerMl: pricePerMl,
            createdAt: getCurrentTimestamp(),
            syncStatus: "pending"
        }

        // Step 5: Save locally first
        await saveToLocalDB("experiences", newExperience)

        // Step 6: Update cider statistics
        await updateCiderStatistics(experienceData.ciderId)

        // Step 7: Update venue analytics
        await updateVenueAnalytics(venueData.id)

        // Step 8: Queue for sync
        syncOperation = {
            type: "CREATE",
            collection: "experiences",
            documentId: newExperience.id,
            data: newExperience,
            timestamp: getCurrentTimestamp()
        }
        this.syncQueue.enqueue(syncOperation)

        IF this.networkMonitor.isOnline() THEN
            await this.syncToFirebase(syncOperation)
        END IF

        RETURN newExperience
    END

FUNCTION processVenueData(venueInput):
    INPUT: Raw venue data from user input
    OUTPUT: Normalized venue data with ID

    BEGIN
        // Normalize venue name for consolidation
        normalizedName = normalizeVenueName(venueInput.name)

        // Check for existing venue
        existingVenue = await findExistingVenue(normalizedName, venueInput.location)

        IF existingVenue IS NOT NULL THEN
            RETURN {
                id: existingVenue.id,
                name: existingVenue.name,
                type: venueInput.type || existingVenue.type,
                location: venueInput.location,
                address: venueInput.address || existingVenue.address
            }
        ELSE
            venueId = generateVenueId(normalizedName, venueInput.location)
            RETURN {
                id: venueId,
                name: normalizedName,
                type: venueInput.type,
                location: venueInput.location,
                address: venueInput.address
            }
        END IF
    END

FUNCTION normalizeVenueName(venueName):
    INPUT: Raw venue name
    OUTPUT: Normalized venue name

    BEGIN
        normalized = venueName.toLowerCase().trim()

        // Apply consolidation rules
        consolidationRules = {
            "tesco": ["tesco extra", "tesco superstore", "tesco express", "tesco metro"],
            "sainsbury's": ["sainsburys", "sainsbury's local", "sainsbury's superstore"],
            "asda": ["asda superstore", "asda supermarket"],
            "morrisons": ["morrisons supermarket"],
            "pub": ["public house", "tavern", "inn"]
        }

        FOR EACH rule IN consolidationRules DO
            FOR EACH variation IN rule.variations DO
                IF normalized.contains(variation) THEN
                    RETURN rule.canonical
                END IF
            END FOR
        END FOR

        RETURN normalized
    END
```

## Query Patterns and Optimization

### Search Operations
```
ALGORITHM: SearchCiders
PURPOSE: Fast fuzzy search with sub-200ms response time

FUNCTION searchCiders(searchQuery, options):
    INPUT: Search query string and search options
    OUTPUT: Promise<SearchResult[]>

    COMPLEXITY:
        Time: O(n log n) where n = number of ciders
        Space: O(n) for result storage

    BEGIN
        IF searchQuery.length < 2 THEN
            RETURN []
        END IF

        normalizedQuery = normalizeSearchQuery(searchQuery)
        queryTokens = tokenizeQuery(normalizedQuery)

        // Search local database for instant results
        candidates = await searchLocalDatabase(queryTokens, options)

        // Score and rank results
        scoredResults = []
        FOR EACH candidate IN candidates DO
            score = calculateSearchScore(candidate, queryTokens)
            IF score > 0.3 THEN  // Minimum relevance threshold
                scoredResults.append({
                    cider: candidate,
                    score: score,
                    highlights: generateHighlights(candidate, queryTokens)
                })
            END IF
        END FOR

        // Sort by relevance score
        scoredResults.sort((a, b) => b.score - a.score)

        // Apply result limit
        resultLimit = options.limit || 20
        RETURN scoredResults.slice(0, resultLimit)
    END

FUNCTION calculateSearchScore(cider, queryTokens):
    INPUT: Cider record and search tokens
    OUTPUT: Relevance score (0-1)

    BEGIN
        score = 0.0

        // Name matching (highest weight)
        nameMatches = countTokenMatches(cider.name, queryTokens)
        score += nameMatches * 0.4

        // Brand matching (high weight)
        brandMatches = countTokenMatches(cider.brand, queryTokens)
        score += brandMatches * 0.3

        // Taste tags matching (medium weight)
        tagMatches = countTokenMatches(cider.tasteTags.join(" "), queryTokens)
        score += tagMatches * 0.2

        // Notes matching (low weight)
        notesMatches = countTokenMatches(cider.notes, queryTokens)
        score += notesMatches * 0.1

        // Boost for exact matches
        IF cider.name.toLowerCase().includes(queryTokens.join(" ")) THEN
            score += 0.3
        END IF

        // Boost by rating (slight preference for higher rated)
        ratingBoost = cider.overallRating / 10 * 0.1
        score += ratingBoost

        RETURN Math.min(score, 1.0)
    END

FUNCTION searchLocalDatabase(queryTokens, options):
    INPUT: Tokenized search query and options
    OUTPUT: Array of candidate ciders

    BEGIN
        // Build SQL query with LIKE operators for fuzzy matching
        whereConditions = []
        params = [getCurrentUserId()]

        FOR EACH token IN queryTokens DO
            whereConditions.append("(name LIKE ? OR brand LIKE ? OR taste_tags LIKE ? OR notes LIKE ?)")
            params.append("%" + token + "%")
            params.append("%" + token + "%")
            params.append("%" + token + "%")
            params.append("%" + token + "%")
        END FOR

        query = "SELECT * FROM ciders WHERE user_id = ? AND (" +
                whereConditions.join(" OR ") + ")"

        IF options.includeDeleted != true THEN
            query += " AND (is_deleted IS NULL OR is_deleted = 0)"
        END IF

        query += " ORDER BY updated_at DESC LIMIT 50"

        RETURN await executeLocalQuery(query, params)
    END
```

### Analytics Queries
```
ALGORITHM: CalculateCollectionAnalytics
PURPOSE: Compute collection completeness and statistics

FUNCTION calculateCollectionAnalytics():
    INPUT: User ID (implicit)
    OUTPUT: Promise<CollectionAnalytics>

    COMPLEXITY:
        Time: O(n) where n = number of ciders + experiences
        Space: O(1) for aggregation

    BEGIN
        analytics = {
            totalCiders: 0,
            totalExperiences: 0,
            totalSpent: 0.0,
            averagePricePerMl: 0.0,
            uniqueCharacteristics: 0,
            completenessPercentage: 0.0,
            breakdown: {}
        }

        // Get all user ciders
        ciders = await queryLocalDB(
            "SELECT * FROM ciders WHERE user_id = ? AND (is_deleted IS NULL OR is_deleted = 0)",
            [getCurrentUserId()]
        )

        analytics.totalCiders = ciders.length

        // Calculate unique characteristics
        characteristicSet = new Set()
        styleBreakdown = {}

        FOR EACH cider IN ciders DO
            // Count unique characteristics
            IF cider.traditionalStyle THEN
                characteristicSet.add("style:" + cider.traditionalStyle)
                styleBreakdown[cider.traditionalStyle] = (styleBreakdown[cider.traditionalStyle] || 0) + 1
            END IF

            FOR EACH category IN cider.appleCategories DO
                characteristicSet.add("apple_category:" + category)
            END FOR

            FOR EACH tag IN cider.tasteTags DO
                characteristicSet.add("taste_tag:" + tag)
            END FOR

            FOR EACH process IN cider.specialProcesses DO
                characteristicSet.add("process:" + process)
            END FOR
        END FOR

        analytics.uniqueCharacteristics = characteristicSet.size

        // Calculate completeness based on theoretical maximum
        theoreticalMax = calculateTheoreticalMaxCharacteristics()
        analytics.completenessPercentage = (analytics.uniqueCharacteristics / theoreticalMax) * 100

        // Get experience statistics
        experiences = await queryLocalDB(
            "SELECT * FROM experiences WHERE user_id = ?",
            [getCurrentUserId()]
        )

        analytics.totalExperiences = experiences.length

        IF experiences.length > 0 THEN
            totalSpent = experiences.reduce((sum, exp) => sum + exp.price, 0)
            analytics.totalSpent = totalSpent

            avgPricePerMl = experiences.reduce((sum, exp) => sum + exp.pricePerMl, 0) / experiences.length
            analytics.averagePricePerMl = avgPricePerMl
        END IF

        analytics.breakdown = {
            styles: styleBreakdown,
            // ... other breakdowns
        }

        RETURN analytics
    END

FUNCTION calculateTheoreticalMaxCharacteristics():
    INPUT: None
    OUTPUT: Number of total possible characteristics

    BEGIN
        // Count all possible characteristics from enums
        totalCharacteristics = 0

        totalCharacteristics += TRADITIONAL_STYLES.length
        totalCharacteristics += APPLE_CATEGORIES.length
        totalCharacteristics += TASTE_TAGS.length
        totalCharacteristics += SPECIAL_PROCESSES.length
        totalCharacteristics += FRUIT_ADDITIONS.length
        totalCharacteristics += SWEETNESS_LEVELS.length
        totalCharacteristics += CARBONATION_LEVELS.length
        totalCharacteristics += CLARITY_LEVELS.length
        totalCharacteristics += COLOR_LEVELS.length

        RETURN totalCharacteristics
    END
```

## Offline Sync Patterns

### Sync Queue Management
```
ALGORITHM: SyncQueueProcessor
PURPOSE: Process offline operations when connectivity restored

CLASS SyncQueueProcessor:
    PROPERTIES:
        queue: PriorityQueue<SyncOperation>
        isProcessing: boolean
        maxRetries: number = 3
        retryDelay: number = 1000  // milliseconds

    FUNCTION enqueue(operation):
        INPUT: SyncOperation to queue
        OUTPUT: void

        BEGIN
            operation.priority = calculatePriority(operation)
            operation.attempts = 0
            operation.queuedAt = getCurrentTimestamp()

            this.queue.enqueue(operation)

            // Save to persistent storage
            await saveToLocalDB("sync_queue", operation)
        END

    FUNCTION processPendingOperations():
        INPUT: None
        OUTPUT: Promise<ProcessResult>

        BEGIN
            IF this.isProcessing THEN
                RETURN // Already processing
            END IF

            this.isProcessing = true
            successCount = 0
            errorCount = 0

            WHILE NOT this.queue.isEmpty() DO
                operation = this.queue.dequeue()

                TRY
                    await this.processOperation(operation)
                    successCount++

                    // Remove from persistent storage
                    await deleteFromLocalDB("sync_queue", operation.id)

                CATCH error AS syncError
                    errorCount++
                    await this.handleSyncError(operation, syncError)
                END TRY
            END WHILE

            this.isProcessing = false

            RETURN {
                success: successCount,
                errors: errorCount,
                completed: true
            }
        END

    FUNCTION processOperation(operation):
        INPUT: SyncOperation to process
        OUTPUT: Promise<void>

        BEGIN
            SWITCH operation.type:
                CASE "CREATE":
                    await this.syncCreate(operation)
                CASE "UPDATE":
                    await this.syncUpdate(operation)
                CASE "DELETE":
                    await this.syncDelete(operation)
                DEFAULT:
                    THROW UnknownOperationError(operation.type)
            END SWITCH
        END

    FUNCTION syncCreate(operation):
        INPUT: Create sync operation
        OUTPUT: Promise<void>

        BEGIN
            document = this.firestore
                .collection(operation.collection)
                .doc(operation.documentId)

            // Check if document already exists (conflict resolution)
            existingDoc = await document.get()

            IF existingDoc.exists THEN
                // Handle conflict - local create vs remote create
                conflictResult = await this.conflictResolver.resolveCreateConflict(
                    operation.data,
                    existingDoc.data()
                )

                IF conflictResult.shouldUpdate THEN
                    await document.update(conflictResult.mergedData)
                END IF
            ELSE
                await document.set(operation.data)
            END IF

            // Update local sync status
            await this.updateLocalSyncStatus(operation.documentId, "synced")
        END

    FUNCTION syncUpdate(operation):
        INPUT: Update sync operation
        OUTPUT: Promise<void>

        BEGIN
            document = this.firestore
                .collection(operation.collection)
                .doc(operation.documentId)

            existingDoc = await document.get()

            IF NOT existingDoc.exists THEN
                // Document was deleted remotely, treat as create
                await document.set(operation.data)
            ELSE
                remoteData = existingDoc.data()

                // Check for version conflicts
                IF remoteData.version > operation.previousVersion THEN
                    // Conflict detected - merge changes
                    mergedData = await this.conflictResolver.resolveUpdateConflict(
                        operation.data,
                        remoteData
                    )
                    await document.update(mergedData)

                    // Update local copy with merged data
                    await this.updateLocalRecord(operation.documentId, mergedData)
                ELSE
                    // No conflict, apply update
                    await document.update(operation.data)
                END IF
            END IF

            await this.updateLocalSyncStatus(operation.documentId, "synced")
        END

    FUNCTION handleSyncError(operation, error):
        INPUT: Failed operation and error
        OUTPUT: Promise<void>

        BEGIN
            operation.attempts++
            operation.lastError = error.message
            operation.lastAttempt = getCurrentTimestamp()

            IF operation.attempts >= this.maxRetries THEN
                // Mark as failed, require manual intervention
                operation.status = "failed"
                await this.updateLocalSyncStatus(operation.documentId, "conflict")

                // Log for user notification
                await this.logSyncFailure(operation, error)
            ELSE
                // Retry with exponential backoff
                retryDelay = this.retryDelay * Math.pow(2, operation.attempts - 1)
                setTimeout(() => {
                    this.queue.enqueue(operation)
                }, retryDelay)
            END IF

            // Update persistent storage
            await updateLocalDB("sync_queue", operation)
        END

    FUNCTION calculatePriority(operation):
        INPUT: SyncOperation
        OUTPUT: Priority score (higher = more urgent)

        BEGIN
            priority = 0

            // User data changes have highest priority
            IF operation.type == "CREATE" OR operation.type == "UPDATE" THEN
                priority += 100
            END IF

            // Recent operations have higher priority
            age = getCurrentTimestamp() - operation.timestamp
            agePriority = Math.max(0, 50 - (age / 1000 / 60))  // Decrease over time
            priority += agePriority

            // Collection operations have priority over individual records
            IF operation.collection == "ciders" THEN
                priority += 20
            ELSE IF operation.collection == "experiences" THEN
                priority += 15
            END IF

            RETURN priority
        END
```

### Conflict Resolution
```
ALGORITHM: ConflictResolver
PURPOSE: Resolve data conflicts between local and remote changes

CLASS ConflictResolver:
    FUNCTION resolveUpdateConflict(localData, remoteData):
        INPUT: Local and remote versions of same record
        OUTPUT: Merged data with conflict resolution

        BEGIN
            mergedData = {...remoteData}

            // Apply conflict resolution rules

            // Last-write-wins for simple fields
            IF localData.updatedAt > remoteData.updatedAt THEN
                mergedData.name = localData.name
                mergedData.brand = localData.brand
                mergedData.abv = localData.abv
                mergedData.notes = localData.notes
            END IF

            // Merge rating history arrays
            localRatings = localData.ratingHistory || []
            remoteRatings = remoteData.ratingHistory || []
            allRatings = [...localRatings, ...remoteRatings]

            // Remove duplicates by timestamp
            uniqueRatings = deduplicateByTimestamp(allRatings)
            mergedData.ratingHistory = uniqueRatings

            // Recalculate average rating
            IF uniqueRatings.length > 0 THEN
                totalRating = uniqueRatings.reduce((sum, r) => sum + r.rating, 0)
                mergedData.overallRating = totalRating / uniqueRatings.length
            END IF

            // Merge taste tags arrays
            localTags = localData.tasteTags || []
            remoteTags = remoteData.tasteTags || []
            mergedTags = [...new Set([...localTags, ...remoteTags])]
            mergedData.tasteTags = mergedTags

            // Use latest timestamp
            mergedData.updatedAt = Math.max(localData.updatedAt, remoteData.updatedAt)
            mergedData.version = Math.max(localData.version, remoteData.version) + 1

            RETURN mergedData
        END

    FUNCTION resolveCreateConflict(localData, remoteData):
        INPUT: Two records created simultaneously
        OUTPUT: Conflict resolution decision

        BEGIN
            // Check if they're actually the same cider
            similarity = calculateSimilarity(
                localData.name + localData.brand,
                remoteData.name + remoteData.brand
            )

            IF similarity > 0.95 THEN
                // Very similar, merge as update conflict
                mergedData = this.resolveUpdateConflict(localData, remoteData)
                RETURN {
                    shouldUpdate: true,
                    mergedData: mergedData
                }
            ELSE
                // Different ciders, keep both but generate new ID for local
                RETURN {
                    shouldUpdate: false,
                    requiresNewId: true
                }
            END IF
        END
```

## Performance Optimization

### Database Indexing
```
ALGORITHM: OptimizeDatabase
PURPOSE: Create indexes for fast query performance

FUNCTION createOptimizedIndexes():
    INPUT: SQLite database connection
    OUTPUT: void

    BEGIN
        // Indexes for common query patterns

        // User-specific queries
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_ciders_user_id ON ciders(user_id)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_experiences_user_id ON experiences(user_id)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_venues_user_id ON venues(user_id)")

        // Search optimization
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_ciders_name ON ciders(name)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_ciders_brand ON ciders(brand)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_ciders_search ON ciders(user_id, name, brand)")

        // Experience queries
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_experiences_cider_id ON experiences(cider_id)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_experiences_date ON experiences(date)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_experiences_venue_id ON experiences(venue_id)")

        // Analytics queries
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_ciders_rating ON ciders(overall_rating)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_experiences_price ON experiences(price_per_ml)")

        // Sync operations
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_sync_queue_status ON sync_queue(status)")
        await executeSQL("CREATE INDEX IF NOT EXISTS idx_sync_queue_priority ON sync_queue(priority)")
    END

FUNCTION optimizeQueryPerformance():
    INPUT: None
    OUTPUT: void

    BEGIN
        // Enable query optimization
        await executeSQL("PRAGMA optimize")

        // Update table statistics
        await executeSQL("ANALYZE")

        // Set optimal cache size (10MB)
        await executeSQL("PRAGMA cache_size = 10000")

        // Enable Write-Ahead Logging for better concurrency
        await executeSQL("PRAGMA journal_mode = WAL")
    END
```

## Error Handling and Recovery

### Database Error Recovery
```
ALGORITHM: DatabaseErrorHandler
PURPOSE: Handle database errors gracefully with recovery mechanisms

FUNCTION handleDatabaseError(error, operation):
    INPUT: Error object and failed operation
    OUTPUT: Recovery action

    BEGIN
        SWITCH error.type:
            CASE "SQLITE_CORRUPT":
                await this.handleCorruption()
            CASE "SQLITE_LOCKED":
                await this.handleLockTimeout(operation)
            CASE "NETWORK_ERROR":
                await this.handleNetworkError(operation)
            CASE "PERMISSION_DENIED":
                await this.handlePermissionError()
            DEFAULT:
                await this.handleGenericError(error, operation)
        END SWITCH
    END

FUNCTION handleCorruption():
    INPUT: None
    OUTPUT: Promise<void>

    BEGIN
        // Attempt database recovery
        TRY
            await executeSQL("PRAGMA integrity_check")
            await executeSQL("VACUUM")
        CATCH recoveryError
            // Corruption too severe, rebuild from Firebase
            await this.rebuildFromFirebase()
        END TRY
    END

FUNCTION rebuildFromFirebase():
    INPUT: None
    OUTPUT: Promise<void>

    BEGIN
        IF NOT this.networkMonitor.isOnline() THEN
            THROW OfflineRecoveryError("Cannot rebuild database while offline")
        END IF

        // Clear corrupted local data
        await this.clearLocalDatabase()

        // Re-download all user data from Firebase
        await this.downloadUserData()

        // Recreate indexes
        await this.createOptimizedIndexes()

        // Notify user of recovery
        await this.notifyUser("Database recovered from cloud backup")
    END
```

This comprehensive database operations layer provides:

1. **Offline-First Architecture**: All operations work offline with automatic sync
2. **Conflict Resolution**: Intelligent merging of concurrent changes
3. **Performance Optimization**: Sub-200ms query responses with proper indexing
4. **Error Recovery**: Robust error handling with automatic recovery mechanisms
5. **Data Integrity**: Validation and referential integrity maintenance
6. **Scalability**: Optimized for personal-scale usage within Firebase free tier

The operations support all critical user workflows while maintaining data consistency and providing a smooth offline/online experience.
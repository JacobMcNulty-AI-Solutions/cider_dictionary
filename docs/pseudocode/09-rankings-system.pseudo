# Rankings System Module
# Best/worst ciders by rating and comprehensive value analysis

## Core Data Structures

STRUCTURE: CiderRanking
    ciderId: string
    overallScore: float
    ratingScore: float
    valueScore: float
    popularityScore: float
    availabilityScore: float
    rankPosition: integer
    category: enum(OVERALL, BY_STYLE, BY_PRODUCER, BY_REGION, BY_PRICE_RANGE)
    sampleSize: integer
    confidenceLevel: float
    lastCalculated: timestamp

STRUCTURE: ValueAnalysis
    ciderId: string
    pricePerML: float
    qualityScore: float
    valueRatio: float // quality/price ratio
    marketPosition: enum(PREMIUM, GOOD_VALUE, BUDGET, OVERPRICED)
    priceSegment: enum(BUDGET, MID_RANGE, PREMIUM, LUXURY)
    competitorComparison: List<CompetitorAnalysis>
    recommendation: string

STRUCTURE: RankingCriteria
    includeRating: boolean
    includePrice: boolean
    includePopularity: boolean
    includeAvailability: boolean
    minimumReviews: integer
    priceRange: {min: float, max: float}
    regionFilter: List<string>
    styleFilter: List<string>
    producerFilter: List<string>
    timeframe: integer // days

STRUCTURE: TrendingAnalysis
    ciderId: string
    currentRank: integer
    previousRank: integer
    rankChange: integer
    trendDirection: enum(UP, DOWN, STABLE)
    velocityScore: float
    momentumIndicator: float
    reasonsForTrend: List<string>

STRUCTURE: RankingInsights
    topPerformers: List<CiderRanking>
    risingStars: List<TrendingAnalysis>
    bestValues: List<ValueAnalysis>
    hiddenGems: List<CiderRanking>
    disappointments: List<CiderRanking>
    marketGaps: List<MarketGap>
    recommendations: List<RankingRecommendation>

## Core Ranking Algorithm

ALGORITHM: CalculateOverallRanking
INPUT: criteria (RankingCriteria)
OUTPUT: rankings (List<CiderRanking>)

BEGIN
    // Filter eligible ciders based on criteria
    eligibleCiders ← FilterCidersByCriteria(criteria)

    rankings ← []

    FOR EACH cider IN eligibleCiders DO
        ranking ← CiderRanking()
        ranking.ciderId ← cider.id
        ranking.category ← criteria.category

        // Calculate component scores
        ranking.ratingScore ← CalculateRatingScore(cider, criteria)
        ranking.valueScore ← CalculateValueScore(cider, criteria)
        ranking.popularityScore ← CalculatePopularityScore(cider, criteria)
        ranking.availabilityScore ← CalculateAvailabilityScore(cider, criteria)

        // Calculate weighted overall score
        ranking.overallScore ← CalculateOverallScore(ranking, criteria)

        // Statistical confidence
        ranking.sampleSize ← GetReviewCount(cider.id)
        ranking.confidenceLevel ← CalculateConfidenceLevel(ranking.sampleSize)

        ranking.lastCalculated ← CurrentTimestamp()

        rankings.append(ranking)
    END FOR

    // Sort by overall score and assign rank positions
    rankings.sortByDescending(overallScore)

    FOR i ← 0 TO rankings.length - 1 DO
        rankings[i].rankPosition ← i + 1
    END FOR

    RETURN rankings
END

ALGORITHM: CalculateOverallScore
INPUT: ranking (CiderRanking), criteria (RankingCriteria)
OUTPUT: overallScore (float)

BEGIN
    // Dynamic weighting based on criteria
    weights ← DetermineWeights(criteria)

    // Base score calculation
    weightedSum ← (ranking.ratingScore * weights.rating) +
                  (ranking.valueScore * weights.value) +
                  (ranking.popularityScore * weights.popularity) +
                  (ranking.availabilityScore * weights.availability)

    totalWeight ← weights.rating + weights.value + weights.popularity + weights.availability

    baseScore ← weightedSum / totalWeight

    // Apply confidence adjustment
    confidenceAdjustment ← ranking.confidenceLevel / 100.0
    adjustedScore ← baseScore * (0.5 + 0.5 * confidenceAdjustment)

    // Apply recency boost for newer highly-rated ciders
    recencyBoost ← CalculateRecencyBoost(ranking.ciderId)
    finalScore ← adjustedScore * (1.0 + recencyBoost)

    RETURN MIN(finalScore, 100.0)
END

## Rating Score Calculation

ALGORITHM: CalculateRatingScore
INPUT: cider (Cider), criteria (RankingCriteria)
OUTPUT: ratingScore (float) // 0-100 scale

BEGIN
    reviews ← Database.getCiderReviews(cider.id, criteria.timeframe)

    IF reviews.length < criteria.minimumReviews THEN
        RETURN 0.0
    END IF

    // Calculate various rating metrics
    averageRating ← AVERAGE(reviews.rating)
    medianRating ← MEDIAN(reviews.rating)
    ratingConsistency ← CalculateRatingConsistency(reviews)

    // Weighted combination favoring consistency
    consistencyWeight ← MIN(0.3, ratingConsistency)
    ratingScore ← (averageRating * (1.0 - consistencyWeight)) +
                  (medianRating * consistencyWeight)

    // Convert 1-5 scale to 0-100 scale
    normalizedScore ← ((ratingScore - 1.0) / 4.0) * 100.0

    // Apply sample size adjustment (Wilson confidence interval)
    adjustedScore ← ApplyWilsonConfidenceInterval(normalizedScore, reviews.length)

    RETURN adjustedScore
END

ALGORITHM: CalculateRatingConsistency
INPUT: reviews (List<Review>)
OUTPUT: consistency (float) // 0-1 scale

BEGIN
    IF reviews.length < 3 THEN
        RETURN 0.0
    END IF

    ratings ← EXTRACT reviews.rating
    standardDeviation ← STANDARD_DEVIATION(ratings)
    mean ← AVERAGE(ratings)

    // Calculate coefficient of variation
    coefficientOfVariation ← standardDeviation / mean

    // Convert to consistency score (inverse of variation)
    consistency ← 1.0 - MIN(1.0, coefficientOfVariation / 0.5)

    RETURN consistency
END

## Value Score Calculation

ALGORITHM: CalculateValueScore
INPUT: cider (Cider), criteria (RankingCriteria)
OUTPUT: valueScore (float) // 0-100 scale

BEGIN
    IF NOT criteria.includePrice THEN
        RETURN 50.0 // Neutral score when price not considered
    END IF

    priceData ← GetCiderPriceData(cider.id)

    IF priceData.isEmpty THEN
        RETURN 0.0
    END IF

    // Calculate price per ML
    averagePricePerML ← AVERAGE(priceData.pricePerML)

    // Get quality score from ratings
    qualityScore ← CalculateQualityScore(cider.id)

    IF qualityScore = 0 THEN
        RETURN 0.0
    END IF

    // Calculate value ratio (quality per unit cost)
    valueRatio ← qualityScore / averagePricePerML

    // Compare against market segment
    marketSegment ← DetermineMarketSegment(averagePricePerML)
    segmentBenchmark ← GetSegmentValueBenchmark(marketSegment, cider.styleId)

    // Relative value score
    relativeValue ← valueRatio / segmentBenchmark

    // Convert to 0-100 scale with logarithmic scaling
    valueScore ← 50.0 + (LOG(relativeValue) * 20.0)

    // Ensure bounds
    valueScore ← MAX(0.0, MIN(100.0, valueScore))

    RETURN valueScore
END

ALGORITHM: DetermineMarketSegment
INPUT: pricePerML (float)
OUTPUT: segment (enum)

BEGIN
    // Market segment thresholds (adjustable by region/style)
    budgetThreshold ← 0.005  // £0.005 per ML
    midRangeThreshold ← 0.015  // £0.015 per ML
    premiumThreshold ← 0.030   // £0.030 per ML

    IF pricePerML <= budgetThreshold THEN
        RETURN BUDGET
    ELSE IF pricePerML <= midRangeThreshold THEN
        RETURN MID_RANGE
    ELSE IF pricePerML <= premiumThreshold THEN
        RETURN PREMIUM
    ELSE
        RETURN LUXURY
    END IF
END

## Popularity Score Calculation

ALGORITHM: CalculatePopularityScore
INPUT: cider (Cider), criteria (RankingCriteria)
OUTPUT: popularityScore (float) // 0-100 scale

BEGIN
    IF NOT criteria.includePopularity THEN
        RETURN 50.0
    END IF

    // Gather popularity metrics
    reviewCount ← Database.getCiderReviewCount(cider.id, criteria.timeframe)
    checkInCount ← Database.getCiderCheckInCount(cider.id, criteria.timeframe)
    wishlistCount ← Database.getCiderWishlistCount(cider.id)
    venueCount ← Database.getVenueCountForCider(cider.id)

    // Weight different popularity signals
    reviewSignal ← LOG(reviewCount + 1) * 0.3
    checkInSignal ← LOG(checkInCount + 1) * 0.4
    wishlistSignal ← LOG(wishlistCount + 1) * 0.2
    availabilitySignal ← LOG(venueCount + 1) * 0.1

    combinedSignal ← reviewSignal + checkInSignal + wishlistSignal + availabilitySignal

    // Normalize against top performers in category
    maxSignal ← GetMaxPopularitySignal(cider.styleId)
    normalizedScore ← (combinedSignal / maxSignal) * 100.0

    RETURN MIN(normalizedScore, 100.0)
END

## Availability Score Calculation

ALGORITHM: CalculateAvailabilityScore
INPUT: cider (Cider), criteria (RankingCriteria)
OUTPUT: availabilityScore (float) // 0-100 scale

BEGIN
    IF NOT criteria.includeAvailability THEN
        RETURN 50.0
    END IF

    venueCount ← 0
    regionCount ← 0

    IF criteria.regionFilter.isEmpty THEN
        // Global availability
        venueCount ← Database.getGlobalVenueCount(cider.id)
        regionCount ← Database.getRegionCount(cider.id)
    ELSE
        // Regional availability
        FOR EACH regionId IN criteria.regionFilter DO
            venueCount ← venueCount + Database.getRegionalVenueCount(cider.id, regionId)
        END FOR
        regionCount ← criteria.regionFilter.length
    END IF

    // Score based on venue density
    venueScore ← MIN(100.0, (venueCount / 10.0) * 100.0) // Max score at 10+ venues

    // Score based on geographic spread
    spreadScore ← MIN(100.0, (regionCount / 5.0) * 100.0) // Max score at 5+ regions

    // Combined availability score
    availabilityScore ← (venueScore * 0.7) + (spreadScore * 0.3)

    RETURN availabilityScore
END

## Trending Analysis

ALGORITHM: CalculateTrendingCiders
INPUT: timeframe (integer), limit (integer)
OUTPUT: trending (List<TrendingAnalysis>)

BEGIN
    currentPeriod ← CurrentTimestamp() - timeframe
    previousPeriod ← currentPeriod - timeframe

    // Get rankings for both periods
    currentRankings ← GetHistoricalRankings(currentPeriod)
    previousRankings ← GetHistoricalRankings(previousPeriod)

    trendingAnalysis ← []

    FOR EACH current IN currentRankings DO
        previous ← FindRankingById(previousRankings, current.ciderId)

        analysis ← TrendingAnalysis()
        analysis.ciderId ← current.ciderId
        analysis.currentRank ← current.rankPosition

        IF previous IS NOT NULL THEN
            analysis.previousRank ← previous.rankPosition
            analysis.rankChange ← previous.rankPosition - current.rankPosition

            // Determine trend direction
            IF analysis.rankChange > 0 THEN
                analysis.trendDirection ← UP
            ELSE IF analysis.rankChange < 0 THEN
                analysis.trendDirection ← DOWN
            ELSE
                analysis.trendDirection ← STABLE
            END IF

            // Calculate velocity (rate of change)
            analysis.velocityScore ← ABS(analysis.rankChange) / timeframe

            // Calculate momentum (accelerating or decelerating)
            analysis.momentumIndicator ← CalculateMomentum(current.ciderId, timeframe)

            // Identify reasons for trend
            analysis.reasonsForTrend ← IdentifyTrendReasons(current.ciderId, timeframe)

            trendingAnalysis.append(analysis)
        END IF
    END FOR

    // Sort by significant positive trends
    trendingAnalysis.sortBy(rankChange DESC, velocityScore DESC)

    RETURN trendingAnalysis.slice(0, limit)
END

## Value Analysis System

ALGORITHM: PerformValueAnalysis
INPUT: priceRange (object), styleId (string), limit (integer)
OUTPUT: valueAnalyses (List<ValueAnalysis>)

BEGIN
    ciders ← Database.getCidersByPriceRangeAndStyle(priceRange, styleId)
    valueAnalyses ← []

    FOR EACH cider IN ciders DO
        analysis ← ValueAnalysis()
        analysis.ciderId ← cider.id

        // Price analysis
        priceData ← GetCiderPriceData(cider.id)
        analysis.pricePerML ← AVERAGE(priceData.pricePerML)

        // Quality analysis
        analysis.qualityScore ← CalculateQualityScore(cider.id)

        IF analysis.qualityScore > 0 AND analysis.pricePerML > 0 THEN
            // Calculate value ratio
            analysis.valueRatio ← analysis.qualityScore / analysis.pricePerML

            // Determine market position
            analysis.marketPosition ← DetermineMarketPosition(analysis)
            analysis.priceSegment ← DetermineMarketSegment(analysis.pricePerML)

            // Competitor comparison
            analysis.competitorComparison ← CompareToCompetitors(cider, analysis)

            // Generate recommendation
            analysis.recommendation ← GenerateValueRecommendation(analysis)

            valueAnalyses.append(analysis)
        END IF
    END FOR

    // Sort by value ratio
    valueAnalyses.sortByDescending(valueRatio)

    RETURN valueAnalyses.slice(0, limit)
END

ALGORITHM: DetermineMarketPosition
INPUT: analysis (ValueAnalysis)
OUTPUT: position (enum)

BEGIN
    // Compare value ratio to market averages
    marketAverage ← GetMarketAverageValueRatio(analysis.priceSegment)

    IF analysis.valueRatio >= marketAverage * 1.3 THEN
        RETURN GOOD_VALUE
    ELSE IF analysis.valueRatio >= marketAverage * 0.8 THEN
        RETURN PREMIUM
    ELSE IF analysis.valueRatio >= marketAverage * 0.5 THEN
        RETURN BUDGET
    ELSE
        RETURN OVERPRICED
    END IF
END

## Hidden Gems Detection

ALGORITHM: IdentifyHiddenGems
INPUT: criteria (RankingCriteria), limit (integer)
OUTPUT: hiddenGems (List<CiderRanking>)

BEGIN
    // Hidden gems: high quality, low popularity, good availability
    allRankings ← CalculateOverallRanking(criteria)

    hiddenGems ← []

    FOR EACH ranking IN allRankings DO
        // Criteria for hidden gem
        isHighQuality ← ranking.ratingScore >= 75.0
        isLowPopularity ← ranking.popularityScore <= 30.0
        isAvailable ← ranking.availabilityScore >= 40.0
        hasEnoughReviews ← ranking.sampleSize >= 5

        IF isHighQuality AND isLowPopularity AND isAvailable AND hasEnoughReviews THEN
            // Calculate hidden gem score
            gemScore ← (ranking.ratingScore * 0.5) +
                      ((100 - ranking.popularityScore) * 0.3) +
                      (ranking.availabilityScore * 0.2)

            ranking.overallScore ← gemScore
            hiddenGems.append(ranking)
        END IF
    END FOR

    // Sort by gem score
    hiddenGems.sortByDescending(overallScore)

    RETURN hiddenGems.slice(0, limit)
END

## Disappointments Analysis

ALGORITHM: IdentifyDisappointments
INPUT: criteria (RankingCriteria), limit (integer)
OUTPUT: disappointments (List<CiderRanking>)

BEGIN
    // Disappointments: high popularity, low rating, or poor value
    allRankings ← CalculateOverallRanking(criteria)

    disappointments ← []

    FOR EACH ranking IN allRankings DO
        cider ← Database.getCider(ranking.ciderId)
        valueAnalysis ← PerformValueAnalysis(
            {min: 0, max: 1000}, cider.styleId, 1000
        )

        cidersValueAnalysis ← FIND valueAnalysis WHERE ciderId = ranking.ciderId

        // Criteria for disappointment
        isHighPopularity ← ranking.popularityScore >= 60.0
        isLowRating ← ranking.ratingScore <= 50.0
        isPoorValue ← cidersValueAnalysis.marketPosition = OVERPRICED
        hasEnoughReviews ← ranking.sampleSize >= 10

        IF (isHighPopularity AND isLowRating) OR
           (isHighPopularity AND isPoorValue) AND hasEnoughReviews THEN

            // Calculate disappointment score
            disappointmentScore ← ranking.popularityScore - ranking.ratingScore

            IF cidersValueAnalysis.marketPosition = OVERPRICED THEN
                disappointmentScore ← disappointmentScore + 20.0
            END IF

            ranking.overallScore ← disappointmentScore
            disappointments.append(ranking)
        END IF
    END FOR

    // Sort by disappointment score
    disappointments.sortByDescending(overallScore)

    RETURN disappointments.slice(0, limit)
END

## Ranking Insights Generation

ALGORITHM: GenerateRankingInsights
INPUT: criteria (RankingCriteria)
OUTPUT: insights (RankingInsights)

BEGIN
    insights ← RankingInsights()

    // Parallel generation of different insights
    topTask ← AsyncTask(CalculateOverallRanking, criteria)
    trendingTask ← AsyncTask(CalculateTrendingCiders, 30, 10)
    valueTask ← AsyncTask(PerformValueAnalysis, {min: 0, max: 1000}, null, 20)
    gemsTask ← AsyncTask(IdentifyHiddenGems, criteria, 15)
    disappointmentsTask ← AsyncTask(IdentifyDisappointments, criteria, 10)

    // Gather results
    insights.topPerformers ← AWAIT topTask
    insights.risingStars ← AWAIT trendingTask
    insights.bestValues ← AWAIT valueTask
    insights.hiddenGems ← AWAIT gemsTask
    insights.disappointments ← AWAIT disappointmentsTask

    // Generate market gap analysis
    insights.marketGaps ← IdentifyMarketGaps(insights.topPerformers)

    // Generate personalized recommendations
    insights.recommendations ← GenerateRankingRecommendations(insights)

    RETURN insights
END

## Performance Optimizations

ALGORITHM: OptimizedRankingCalculation
INPUT: criteria (RankingCriteria), useCache (boolean)
OUTPUT: rankings (List<CiderRanking>)

BEGIN
    cacheKey ← GenerateCacheKey(criteria)

    IF useCache THEN
        cached ← Cache.get(cacheKey)
        IF cached IS NOT NULL AND
           (CurrentTime() - cached.lastCalculated) < GetCacheTTL(criteria) THEN
            RETURN cached
        END IF
    END IF

    // Use pre-calculated metrics where possible
    rankings ← []

    // Batch load all required data
    ciders ← FilterCidersByCriteria(criteria)
    reviewData ← BatchLoadReviewData(ciders)
    priceData ← BatchLoadPriceData(ciders)
    popularityData ← BatchLoadPopularityData(ciders)

    // Parallel processing for large datasets
    IF ciders.length > 1000 THEN
        rankings ← ParallelRankingCalculation(ciders, reviewData, priceData, popularityData)
    ELSE
        rankings ← SequentialRankingCalculation(ciders, reviewData, priceData, popularityData)
    END IF

    // Cache results with appropriate TTL
    ttl ← GetCacheTTL(criteria)
    Cache.set(cacheKey, rankings, ttl)

    RETURN rankings
END

## Statistical Validation

ALGORITHM: ApplyWilsonConfidenceInterval
INPUT: score (float), sampleSize (integer)
OUTPUT: adjustedScore (float)

BEGIN
    // Wilson confidence interval for binomial proportions
    // Adjusts scores based on sample size confidence

    IF sampleSize <= 0 THEN
        RETURN 0.0
    END IF

    // Convert score to proportion (0-1)
    proportion ← score / 100.0

    // Z-score for 95% confidence
    z ← 1.96

    // Wilson interval calculation
    denominator ← 1 + (z * z) / sampleSize
    adjustment ← z * SQRT((proportion * (1 - proportion) + z * z / (4 * sampleSize)) / sampleSize)

    lowerBound ← (proportion + z * z / (2 * sampleSize) - adjustment) / denominator
    upperBound ← (proportion + z * z / (2 * sampleSize) + adjustment) / denominator

    // Use lower bound as conservative estimate
    adjustedProportion ← lowerBound

    // Convert back to 0-100 scale
    adjustedScore ← adjustedProportion * 100.0

    RETURN MAX(0.0, adjustedScore)
END

## API Endpoints

ENDPOINT: GET /api/rankings/overall
QUERY: criteria (RankingCriteria)
RETURNS: List<CiderRanking> with pagination

ENDPOINT: GET /api/rankings/trending
QUERY: timeframe, limit
RETURNS: List<TrendingAnalysis>

ENDPOINT: GET /api/rankings/value-analysis
QUERY: priceRange, styleId, limit
RETURNS: List<ValueAnalysis>

ENDPOINT: GET /api/rankings/hidden-gems
QUERY: criteria, limit
RETURNS: List<CiderRanking>

ENDPOINT: GET /api/rankings/insights
QUERY: criteria
RETURNS: RankingInsights

ENDPOINT: POST /api/rankings/custom
BODY: CustomRankingCriteria
RETURNS: List<CiderRanking> with custom weighting

## Error Handling and Edge Cases

1. **Insufficient Data**: Minimum sample size requirements with confidence indicators
2. **Price Data Missing**: Graceful degradation without value scoring
3. **New Ciders**: Special handling for ciders with limited history
4. **Seasonal Variations**: Time-based adjustments for seasonal ciders
5. **Currency Differences**: Normalization for international comparisons

## Time Complexity Analysis

- Overall Ranking: O(n log n) where n = number of eligible ciders
- Trending Analysis: O(n) with indexed historical data
- Value Analysis: O(n × m) where m = price data points per cider
- Hidden Gems: O(n) with pre-calculated scores
- Batch Operations: O(n) with parallel processing optimizations

## Space Complexity Analysis

- Ranking Storage: O(n) where n = ranked ciders
- Cache Usage: O(c × r) where c = criteria combinations, r = results per criteria
- Temporary Calculations: O(n) for intermediate score calculations
- Historical Data: O(h × n) where h = historical periods tracked